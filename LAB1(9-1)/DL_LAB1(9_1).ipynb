{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Introduction of PyTorch Tensors and Basic Operations\n",
        "a) PyTorch Tensors: Initialization & Data Types"
      ],
      "metadata": {
        "id": "Mcs2qAtJ87vO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyfXm5DN6TH4",
        "outputId": "ba15bf5b-73ab-4268-8187-3c64ab92de42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]]) tensor([[0.3393, 0.5335],\n",
            "        [0.5261, 0.0173]]) tensor([1., 2., 3.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([1, 2, 3])\n",
        "print(a)\n",
        "\n",
        "b = torch.zeros((2,3))\n",
        "c = torch.zeros((3,3))\n",
        "\n",
        "d = torch.rand((2,2))\n",
        "\n",
        "e = torch.tensor([1,2,3], dtype=torch.float32)\n",
        "print(b, c, d, e)\n",
        "\n",
        "# Common Data Types\n",
        "# torch.int32, torch.float32, torch.float64, torch.bool"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Tensor Operations"
      ],
      "metadata": {
        "id": "W3NdCdWA9F6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithmetic Operation\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])\n",
        "\n",
        "print(x + y)\n",
        "print(x * y)\n",
        "print(torch.add(x, y))\n",
        "\n",
        "\n",
        "# Broadcasting\n",
        "a = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "b = torch.tensor([1, 2, 3])\n",
        "\n",
        "print(a + b)\n",
        "\n",
        "# Indexing & Slicing\n",
        "t = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "print(t[0])        # First row\n",
        "print(t[:, 1])     # Second column\n",
        "print(t[1, 2])     # Specific element\n",
        "\n",
        "# Reshaping\n",
        "\n",
        "x = torch.arange(12)\n",
        "y = x.view(3, 4)\n",
        "z = x.reshape(2, 6)\n",
        "\n",
        "print(y)\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBE_ZQxi8eaR",
        "outputId": "419e079e-1241-482b-a1e7-eff67728c79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 7, 9])\n",
            "tensor([ 4, 10, 18])\n",
            "tensor([5, 7, 9])\n",
            "tensor([[2, 4, 6],\n",
            "        [5, 7, 9]])\n",
            "tensor([1, 2, 3])\n",
            "tensor([2, 5])\n",
            "tensor(6)\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Automatic Differentiation (Autograd)"
      ],
      "metadata": {
        "id": "e4s0yfG1-dic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x**3 + 2*x\n",
        "\n",
        "y.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWuUspgR8R-G",
        "outputId": "a1291724-7025-4d3a-98b9-bb1b1d6b6575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Linear Algebra Operations using TensorFlow"
      ],
      "metadata": {
        "id": "RPzFgvS8--Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "A = tf.constant([[1,2],[3,4]], dtype = tf.float32)\n",
        "B = tf.constant([[5,6],[7,8]], dtype = tf.float32)\n",
        "\n",
        "print(tf.add(A, B))\n",
        "print(tf.subtract(A, B))\n",
        "\n",
        "print(tf.matmul(A, B))\n",
        "print(tf.transpose(A))\n",
        "print(tf.linalg.inv(A))\n",
        "eigenvalues = tf.linalg.eig(A)\n",
        "print(eigenvalues)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMp9JzYg_A83",
        "outputId": "2e60033d-957f-413e-ecc2-203d41e064f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 6.  8.]\n",
            " [10. 12.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-4. -4.]\n",
            " [-4. -4.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[19. 22.]\n",
            " [43. 50.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 3.]\n",
            " [2. 4.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-2.0000002   1.0000001 ]\n",
            " [ 1.5000001  -0.50000006]], shape=(2, 2), dtype=float32)\n",
            "(<tf.Tensor: shape=(2,), dtype=complex64, numpy=array([-0.37228122+0.j,  5.372281  +0.j], dtype=complex64)>, <tf.Tensor: shape=(2, 2), dtype=complex64, numpy=\n",
            "array([[-0.8245648 +0.j, -0.41597357+0.j],\n",
            "       [ 0.56576747+0.j, -0.90937674+0.j]], dtype=complex64)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) AND & OR Gates using Perceptron"
      ],
      "metadata": {
        "id": "n4ivXwLeBGe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(x1, x2, w1, w2, b):\n",
        "  y = x1*w1 + x2*w2 + b\n",
        "  return 1 if y >= 0 else 0\n",
        "\n",
        "print(\"AND GATE\")\n",
        "for x1 in [0,1]:\n",
        "  for x2 in [0,1]:\n",
        "    print(x1, x2, perceptron(x1, x2, 1, 1, -1.5))\n",
        "\n",
        "print(\"OR GATE\")\n",
        "for x1 in [0,1]:\n",
        "  for x2 in [0,1]:\n",
        "    print(x1, x2, perceptron(x1, x2, 1, 1, -0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpL9OsFMBKxG",
        "outputId": "bfe27c24-a341-479f-a0a0-1cbfcec76c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND GATE\n",
            "0 0 0\n",
            "0 1 0\n",
            "1 0 0\n",
            "1 1 1\n",
            "OR GATE\n",
            "0 0 0\n",
            "0 1 1\n",
            "1 0 1\n",
            "1 1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) XOR Problem using PyTorch Neural Network"
      ],
      "metadata": {
        "id": "XthRGR6lCQ4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "X = torch.tensor([[0., 0.],\n",
        "                  [0., 1.],\n",
        "                  [1., 0.],\n",
        "                  [1., 1.]])\n",
        "\n",
        "y = torch.tensor([[0.],\n",
        "                  [1.],\n",
        "                  [1.],\n",
        "                  [0.]])\n",
        "\n",
        "class XORNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(XORNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(2, 4)\n",
        "    self.fc2 = nn.Linear(4, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.sigmoid(self.fc2(x))\n",
        "    return x\n",
        "\n",
        "model = XORNet()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(2000):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 400 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(X)\n",
        "    print(torch.round(predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHhoKqArBniX",
        "outputId": "a4026454-ae78-41cb-b4a5-1f3fcd30c4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7071200609207153\n",
            "Epoch 400, Loss: 0.4773862063884735\n",
            "Epoch 800, Loss: 0.47738614678382874\n",
            "Epoch 1200, Loss: 0.4773860275745392\n",
            "Epoch 1600, Loss: 0.4773859977722168\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Implement Simple below Neural Network to solve regression problem."
      ],
      "metadata": {
        "id": "wx5nPrDUE6pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load & Preprocess Data\n",
        "\n",
        "path = \"/content/house_price_full+(2) - house_price_full+(2).csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Normalize\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "y = (y - y.mean()) / y.std()\n",
        "\n",
        "\n",
        "# Activation Functions\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "W1 = np.random.randn(X.shape[1], 2)\n",
        "b1 = np.zeros((1, 2))\n",
        "\n",
        "W2 = np.random.randn(2, 1)\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def forward(X):\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    return z1, a1, z2\n",
        "\n",
        "\n",
        "# Loss Function (MSE)\n",
        "\n",
        "def mse(y, y_hat):\n",
        "    return np.mean((y - y_hat) ** 2)\n",
        "\n",
        "# Backpropagation\n",
        "\n",
        "def backward(X, y, z1, a1, y_hat):\n",
        "    global W1, b1, W2, b2\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dz2 = y_hat - y\n",
        "    dW2 = np.dot(a1.T, dz2) / m\n",
        "    db2 = np.mean(dz2, axis=0, keepdims=True)\n",
        "\n",
        "    da1 = np.dot(dz2, W2.T)\n",
        "    dz1 = da1 * relu_derivative(z1)\n",
        "    dW1 = np.dot(X.T, dz1) / m\n",
        "    db1 = np.mean(dz1, axis=0, keepdims=True)\n",
        "\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "epochs = 3000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    z1, a1, y_hat = forward(X)\n",
        "    loss = mse(y, y_hat)\n",
        "    backward(X, y, z1, a1, y_hat)\n",
        "\n",
        "    if epoch % 300 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "sample = X[0].reshape(1, -1)\n",
        "_, _, prediction = forward(sample)\n",
        "\n",
        "print(\"\\nPrediction (normalized):\", prediction)\n",
        "print(\"Actual (normalized):\", y[0])\n"
      ],
      "metadata": {
        "id": "sj0RdHEFE8ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f37293d-8dca-4940-a560-a457fb504b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.8087\n",
            "Epoch 300, Loss: 0.5351\n",
            "Epoch 600, Loss: 0.5266\n",
            "Epoch 900, Loss: 0.5216\n",
            "Epoch 1200, Loss: 0.5177\n",
            "Epoch 1500, Loss: 0.5152\n",
            "Epoch 1800, Loss: 0.5133\n",
            "Epoch 2100, Loss: 0.5119\n",
            "Epoch 2400, Loss: 0.5105\n",
            "Epoch 2700, Loss: 0.5091\n",
            "\n",
            "Prediction (normalized): [[-0.42579837]]\n",
            "Actual (normalized): [-0.68877874]\n"
          ]
        }
      ]
    }
  ]
}